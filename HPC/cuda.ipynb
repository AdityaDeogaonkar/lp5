{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1XXHREWWfsg",
        "outputId": "d0872b81-f8d3-418e-bb04-77c28b40d686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQMRcRa0Xxa_",
        "outputId": "0d43bdc0-aad5-4c33-c43f-fdb1cb77aee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-tr_p9jv1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-tr_p9jv1\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=19f26f1403150301d93eb192ff32614d02ff4da6fa90e482784e83f41f0cadab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7x0f_921/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRENpGO0ZGiU",
        "outputId": "a7bf6671-b069-4ed8-aef6-abac13ff2659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4ExqOLYNZtfe",
        "outputId": "551e6ec3-e797-498d-ddf4-9d9f9a5d2e16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/vector_add.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%cuda --name vector_add.cu\n",
        "#include<iostream>\n",
        "#include<bits/stdc++.h>\n",
        "#include<cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "using namespace std;\n",
        "\n",
        "void fill_array(int *arr,int size){\n",
        "    for(int i = 0;i < size; i++){\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void add_cpu(int *arr1, int *arr2, int *result, int size){\n",
        "    for(int i = 0;i < size; i++){\n",
        "        result[i] = arr1[i] + arr2[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *arr, int size){\n",
        "    for(int i = 0; i < size; i++){\n",
        "        cout << arr[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "__global__ void add(int *arr1, int *arr2, int *arr3,int size){\n",
        "    int block_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(block_id < size){\n",
        "        arr3[block_id] = arr1[block_id] + arr2[block_id];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int *arr1_cpu,*arr2_cpu,*result_cpu;\n",
        "    int size;\n",
        "    cout << \"Enter size of vector: \";\n",
        "    cin >> size;\n",
        "\n",
        "    arr1_cpu = new int[size];\n",
        "    arr2_cpu = new int[size];\n",
        "    result_cpu = new int[size];\n",
        "\n",
        "    fill_array(arr1_cpu,size);\n",
        "    cout << \"Array 1: \";\n",
        "    print_matrix(arr1_cpu,size);\n",
        "    fill_array(arr2_cpu,size);\n",
        "    cout << \"Array 2: \";\n",
        "    print_matrix(arr2_cpu,size);\n",
        "\n",
        "    int *arr1_gpu,*arr2_gpu,*result_gpu;\n",
        "    \n",
        "    cudaMallocManaged(&arr1_gpu, size * sizeof(int));\n",
        "    cudaMallocManaged(&arr2_gpu, size * sizeof(int));\n",
        "    cudaMallocManaged(&result_gpu, size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(arr1_gpu,arr1_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(arr2_gpu,arr2_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaEvent_t start,stop;\n",
        "    float elapsedTime;\n",
        "    \n",
        "    dim3 dimGrid(size + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "    dim3 dimBlock(BLOCK_SIZE);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "    add<<<dimGrid,dimBlock>>>(arr1_gpu,arr2_gpu,result_gpu,size);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaMemcpy(result_cpu,result_gpu,size * sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    cout << \"GPU result:\\n\";\n",
        "    print_matrix(result_cpu,size);\n",
        "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "    cudaFree(arr1_gpu);\n",
        "    cudaFree(arr2_gpu);\n",
        "    cudaFree(result_gpu);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "    add_cpu(arr1_cpu,arr2_cpu,result_cpu,size);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cout << \"CPU result:\\n\";\n",
        "    print_matrix(result_cpu,size);\n",
        "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DLecw_AJamEY"
      },
      "outputs": [],
      "source": [
        "!nvcc /content/src/vector_add.cu -o /content/src/vector_add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRnx20HcawRI",
        "outputId": "abc46ef5-ccf0-40cd-c639-72c31303034a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter size of vector: 4\n",
            "Array 1: 83 86 77 15 \n",
            "Array 2: 93 35 86 92 \n",
            "GPU result:\n",
            "176 121 163 107 \n",
            "Elapsed Time = 0.013824 milliseconds\n",
            "CPU result:\n",
            "176 121 163 107 \n",
            "Elapsed Time = 0.002752 milliseconds\n"
          ]
        }
      ],
      "source": [
        "!/content/src/vector_add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9ypLYwrTa1EF",
        "outputId": "c3c02635-d57c-4e6f-bfdb-358bbe59c3ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/matrix_multiply.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "%%cuda --name matrix_multiply.cu\n",
        "#include<iostream>\n",
        "#include<bits/stdc++.h>\n",
        "#include<cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "\n",
        "void initialize_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            array[i*cols + j] = rand() % 10;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            cout << array[i*cols + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows,int c_cols){\n",
        "    for(int i = 0; i < c_rows; i++){\n",
        "        for(int j = 0; j < c_cols; j++){\n",
        "            int sum = 0;\n",
        "            for(int k = 0; k < common; k++){\n",
        "                sum += a[i*common + k] * b[k*c_cols + j];\n",
        "            }\n",
        "            c[i*c_cols + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__ void matrix_multiply(int *a, int *b, int *c, int c_rows, int common, int c_cols)\n",
        "{\n",
        "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int sum=0;\n",
        "   \n",
        "    if(col < c_cols && row < c_rows) {\n",
        "      for(int j = 0 ;j < common;j++)\n",
        "      {\n",
        "          sum += a[row*common+j] * b[j*c_cols+col];\n",
        "      }\n",
        "      c[c_cols*row+col]=sum;\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int A_rows, A_cols, B_rows, B_cols, C_rows, C_cols;\n",
        "    cout << \"Dimensions of matrix 1:\\n\";\n",
        "    cout << \"Rows: \";\n",
        "    cin >> A_rows;\n",
        "    cout << \"Columns: \";\n",
        "    cin >> A_cols;\n",
        "    cout << \"Dimensions of matrix 2:\\n\";\n",
        "    cout << \"Rows: \" << A_cols << endl << \"Columns: \";\n",
        "    cin >> B_cols;\n",
        "    B_rows = A_cols;\n",
        "    C_rows = A_rows;\n",
        "    C_cols = B_cols;\n",
        "\n",
        "    int A_size = A_rows * A_cols;\n",
        "    int B_size = B_rows * B_cols;\n",
        "    int C_size = C_rows * C_cols;\n",
        "\n",
        "    int *A, *B, *C;\n",
        "    int *m1,*m2,*result;\n",
        "\n",
        "    A = new int[A_size];\n",
        "    B = new int[B_size];\n",
        "    C = new int[C_size];\n",
        "\n",
        "    initialize_matrix(A,A_rows,A_cols);\n",
        "    cout << \"Matrix 1\\n\";\n",
        "    print_matrix(A,A_rows,A_cols);\n",
        "    initialize_matrix(B,B_rows,B_cols);\n",
        "    cout << \"Matrix 2\\n\";\n",
        "    print_matrix(B,B_rows,B_cols);\n",
        "\n",
        "    cudaMallocManaged(&m1, A_size * sizeof(int));\n",
        "    cudaMallocManaged(&m2, B_size * sizeof(int));\n",
        "    cudaMallocManaged(&result, C_size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(m1,A,A_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(m2,B,B_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimGrid(A_rows + BLOCK_SIZE  - 1 / BLOCK_SIZE, B_cols + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "    dim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\n",
        "    float gpu_elapsed_time;\n",
        "    cudaEvent_t gpu_start,gpu_stop;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiply<<<dimGrid,dimBlock>>>(m1,m2,result,C_rows,A_cols,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    cout << \"GPU result:\\n\";\n",
        "    print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiplication_cpu(A,B,C,A_cols,C_rows,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cout << \"CPU result:\\n\";\n",
        "    print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"CPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaFree(m1);\n",
        "    cudaFree(m2);\n",
        "    cudaFree(result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t6NYJo5VMfEr"
      },
      "outputs": [],
      "source": [
        "!nvcc /content/src/matrix_multiply.cu -o /content/src/matrix_multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KATF5dtXMwgL",
        "outputId": "12eb7ad5-b0cf-4cda-bc06-e4d2d2a16ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of matrix 1:\n",
            "Rows: 5\n",
            "Columns: 6\n",
            "Dimensions of matrix 2:\n",
            "Rows: 6\n",
            "Columns: 5\n",
            "Matrix 1\n",
            "3 6 7 5 3 5 \n",
            "6 2 9 1 2 7 \n",
            "0 9 3 6 0 6 \n",
            "2 6 1 8 7 9 \n",
            "2 0 2 3 7 5 \n",
            "Matrix 2\n",
            "9 2 2 8 9 \n",
            "7 3 6 1 2 \n",
            "9 3 1 9 4 \n",
            "7 8 4 5 0 \n",
            "3 6 1 0 6 \n",
            "3 2 0 6 1 \n",
            "GPU result:\n",
            "191 113 72 148 90 \n",
            "183 79 39 178 113 \n",
            "150 96 81 102 36 \n",
            "173 149 80 125 85 \n",
            "93 86 25 79 73 \n",
            "GPU Elapsed time is: 0.029344 milliseconds\n",
            "CPU result:\n",
            "191 113 72 148 90 \n",
            "183 79 39 178 113 \n",
            "150 96 81 102 36 \n",
            "173 149 80 125 85 \n",
            "93 86 25 79 73 \n",
            "CPU Elapsed time is: 0.002048 milliseconds\n"
          ]
        }
      ],
      "source": [
        "!/content/src/matrix_multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SAu53_m4Ne0n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}